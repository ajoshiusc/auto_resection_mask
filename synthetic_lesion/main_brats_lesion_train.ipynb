{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install torch monai nilearn torchio scikit-learn numpy nibabel\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchio\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import Compose, AddChannel, ScaleIntensity, ToTensor, Resample, EnsureChannelFirst, CropOrPad, RandSpatialCrop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.data import NiftiDataset\n",
    "import nilearn.image as nilimage\n",
    "import nilearn.plotting as nilplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Define the path to your BRATS data directory and lesion segmentations\n",
    "brats_data_dir = '/path/to/brats_data'\n",
    "segmentations_dir = '/path/to/lesion_segmentations'\n",
    "\n",
    "# Create a list of subject and label image paths\n",
    "subject_files = []\n",
    "label_files = []\n",
    "for subject_id in os.listdir(brats_data_dir):\n",
    "    subject_dir = os.path.join(brats_data_dir, subject_id)\n",
    "    subject_files.append(os.path.join(subject_dir, 'T1.nii.gz'))\n",
    "    label_files.append(os.path.join(segmentations_dir, f'{subject_id}_lesion.nii.gz'))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_subjects, val_subjects, train_labels, val_labels = train_test_split(\n",
    "    subject_files, label_files, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define MONAI transforms for preprocessing\n",
    "train_transforms = Compose([\n",
    "    ScaleIntensity(),\n",
    "    EnsureChannelFirst(),\n",
    "    AddChannel(),\n",
    "    Resample((1, 1, 1)),\n",
    "    CropOrPad((128, 128, 128)),\n",
    "    RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    ScaleIntensity(),\n",
    "    EnsureChannelFirst(),\n",
    "    AddChannel(),\n",
    "    Resample((1, 1, 1)),\n",
    "    CropOrPad((128, 128, 128)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Create NiftiDataset for training and validation\n",
    "train_ds = NiftiDataset(\n",
    "    image_files=train_subjects,\n",
    "    label_files=train_labels,\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "val_ds = NiftiDataset(\n",
    "    image_files=val_subjects,\n",
    "    label_files=val_labels,\n",
    "    transform=val_transforms\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, num_workers=4)\n",
    "\n",
    "# Create U-Net model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_function = DiceLoss(sigmoid=True)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Create a Dice metric for validation\n",
    "dice_metric = DiceMetric(include_background=True, reduction='mean')\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = batch['image'].to(device), batch['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        metric = dice_metric(y_pred=outputs, y=targets)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] Dice: {metric.item():.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'unet_brats_model.pt')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
